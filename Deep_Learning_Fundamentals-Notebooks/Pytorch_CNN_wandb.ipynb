{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0d4352d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define transformation: convert to tensor and normalize to [0, 1]\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download and load the FashionMNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader for batching\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Example: get the shape of the first training image\n",
    "images, labels = next(iter(train_loader))\n",
    "print(images[0].shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ea4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes in Fashion MNIST\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # First conv block\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Second conv block\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16548f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Failed to detect the name of this notebook. You can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: gsayantan1999 to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\sayantghosh\\Desktop\\ML-DL-Code-Scratch\\Deep_Learning_Fundamentals-Notebooks\\wandb\\run-20250510_021512-i1kqe4iv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gsayantan1999/fashion-mnist-cnn/runs/i1kqe4iv' target=\"_blank\">lucky-waterfall-1</a></strong> to <a href='https://wandb.ai/gsayantan1999/fashion-mnist-cnn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gsayantan1999/fashion-mnist-cnn' target=\"_blank\">https://wandb.ai/gsayantan1999/fashion-mnist-cnn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gsayantan1999/fashion-mnist-cnn/runs/i1kqe4iv' target=\"_blank\">https://wandb.ai/gsayantan1999/fashion-mnist-cnn/runs/i1kqe4iv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import wandb\n",
    "import random\n",
    "import math\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(\n",
    "    project=\"fashion-mnist-cnn\",\n",
    "    config={\n",
    "        \"epochs\": 10,\n",
    "        \"batch_size\": 64,\n",
    "        \"lr\": 0.001,\n",
    "        \"model_type\": \"CNN\",\n",
    "        \"dataset\": \"FashionMNIST\",\n",
    "        \"optimizer\": \"Adam\"\n",
    "    }\n",
    ")\n",
    "config = wandb.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb763998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch 1/10 - 61.5s - Train loss: 0.4992, Train acc: 0.8173 - Val loss: 0.3472, Val acc: 0.8737\n",
      "Epoch 2/10 - 64.4s - Train loss: 0.3191, Train acc: 0.8827 - Val loss: 0.2981, Val acc: 0.8932\n",
      "Epoch 3/10 - 49.6s - Train loss: 0.2741, Train acc: 0.8995 - Val loss: 0.2617, Val acc: 0.9052\n",
      "Epoch 4/10 - 51.2s - Train loss: 0.2422, Train acc: 0.9115 - Val loss: 0.2567, Val acc: 0.9055\n",
      "Epoch 5/10 - 53.6s - Train loss: 0.2194, Train acc: 0.9190 - Val loss: 0.2357, Val acc: 0.9162\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[WinError 1314] A required privilege is not held by the client: 'c:\\\\Users\\\\sayantghosh\\\\Desktop\\\\ML-DL-Code-Scratch\\\\Deep_Learning_Fundamentals-Notebooks\\\\fashion_mnist_cnn_epoch_5.pt' -> 'c:\\\\Users\\\\sayantghosh\\\\Desktop\\\\ML-DL-Code-Scratch\\\\Deep_Learning_Fundamentals-Notebooks\\\\wandb\\\\run-20250510_021512-i1kqe4iv\\\\files\\\\fashion_mnist_cnn_epoch_5.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 131\u001b[0m\n\u001b[0;32m    123\u001b[0m checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfashion_mnist_cnn_epoch_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    124\u001b[0m torch\u001b[38;5;241m.\u001b[39msave({\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch_val_loss,\n\u001b[0;32m    130\u001b[0m }, checkpoint_path)\n\u001b[1;32m--> 131\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:406\u001b[0m, in \u001b[0;36m_log_to_run.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    403\u001b[0m     run_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_attach_id\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m wb_logging\u001b[38;5;241m.\u001b[39mlog_to_run(run_id):\n\u001b[1;32m--> 406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:464\u001b[0m, in \u001b[0;36m_raise_if_finished.<locals>.wrapper_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Run, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m     )\n\u001b[0;32m    472\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(message)\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:451\u001b[0m, in \u001b[0;36m_attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    449\u001b[0m         _is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2175\u001b[0m, in \u001b[0;36mRun.save\u001b[1;34m(self, glob_str, base_path, policy)\u001b[0m\n\u001b[0;32m   2169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2170\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnly \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlive\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnow\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m policies are currently supported.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2171\u001b[0m     )\n\u001b[0;32m   2173\u001b[0m resolved_base_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPurePath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(base_path))\n\u001b[1;32m-> 2175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_glob_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresolved_base_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2179\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\site-packages\\wandb\\sdk\\wandb_run.py:2234\u001b[0m, in \u001b[0;36mRun._save\u001b[1;34m(self, glob_path, base_path, policy)\u001b[0m\n\u001b[0;32m   2231\u001b[0m     \u001b[38;5;66;03m# Delete the symlink if it exists.\u001b[39;00m\n\u001b[0;32m   2232\u001b[0m     target_path\u001b[38;5;241m.\u001b[39munlink(missing_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2234\u001b[0m     \u001b[43mtarget_path\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;66;03m# Inform users that new files aren't detected automatically.\u001b[39;00m\n\u001b[0;32m   2237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m had_symlinked_files \u001b[38;5;129;01mand\u001b[39;00m is_star_glob:\n",
      "File \u001b[1;32mc:\\Users\\sayantghosh\\AppData\\Local\\anaconda3\\envs\\genai\\Lib\\pathlib.py:1386\u001b[0m, in \u001b[0;36mPath.symlink_to\u001b[1;34m(self, target, target_is_directory)\u001b[0m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(os, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymlink\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mos.symlink() not available on this system\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1386\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msymlink\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_is_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1314] A required privilege is not held by the client: 'c:\\\\Users\\\\sayantghosh\\\\Desktop\\\\ML-DL-Code-Scratch\\\\Deep_Learning_Fundamentals-Notebooks\\\\fashion_mnist_cnn_epoch_5.pt' -> 'c:\\\\Users\\\\sayantghosh\\\\Desktop\\\\ML-DL-Code-Scratch\\\\Deep_Learning_Fundamentals-Notebooks\\\\wandb\\\\run-20250510_021512-i1kqe4iv\\\\files\\\\fashion_mnist_cnn_epoch_5.pt'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model\n",
    "model = CNN()\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Log model architecture to wandb\n",
    "wandb.watch(model, log=\"all\", log_freq=100)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = config.epochs\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# Calculate steps per epoch for logging\n",
    "n_steps_per_epoch = math.ceil(len(train_loader.dataset) / config.batch_size)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for step, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Log metrics to wandb per step (not too frequently to avoid slowdowns)\n",
    "        if step % 20 == 0:\n",
    "            wandb.log({\n",
    "                \"train/batch_loss\": loss.item(),\n",
    "                \"train/epoch\": epoch + (step + 1) / n_steps_per_epoch\n",
    "            })\n",
    "    \n",
    "    epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_train_acc = correct / total\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    train_accs.append(epoch_train_acc)\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Create lists to store predictions for visualization\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(test_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Store some predictions for visualization (just from the first batch)\n",
    "            if i == 0 and epoch == num_epochs - 1:\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_images.extend(images.cpu().numpy())\n",
    "    \n",
    "    epoch_val_loss = running_loss / len(test_loader.dataset)\n",
    "    epoch_val_acc = correct / total\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    val_accs.append(epoch_val_acc)\n",
    "    \n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"train/epoch_loss\": epoch_train_loss,\n",
    "        \"train/accuracy\": epoch_train_acc,\n",
    "        \"val/epoch_loss\": epoch_val_loss,\n",
    "        \"val/accuracy\": epoch_val_acc,\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"time_per_epoch\": time.time() - start_time\n",
    "    })\n",
    "    \n",
    "    # Print statistics\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - {epoch_time:.1f}s - \"\n",
    "          f\"Train loss: {epoch_train_loss:.4f}, Train acc: {epoch_train_acc:.4f} - \"\n",
    "          f\"Val loss: {epoch_val_loss:.4f}, Val acc: {epoch_val_acc:.4f}\")\n",
    "    \n",
    "    # # Save model checkpoints to wandb\n",
    "    # if (epoch + 1) % 5 == 0 or epoch == num_epochs - 1:\n",
    "    #     checkpoint_path = f\"fashion_mnist_cnn_epoch_{epoch+1}.pt\"\n",
    "    #     torch.save({\n",
    "    #         'epoch': epoch,\n",
    "    #         'model_state_dict': model.state_dict(),\n",
    "    #         'optimizer_state_dict': optimizer.state_dict(),\n",
    "    #         'train_loss': epoch_train_loss,\n",
    "    #         'val_loss': epoch_val_loss,\n",
    "    #     }, checkpoint_path)\n",
    "    #     wandb.save(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d2efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the final model\n",
    "final_model_path = \"fashion_mnist_cnn_final.pt\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "wandb.save(final_model_path)\n",
    "\n",
    "# Log confusion matrix\n",
    "if len(all_preds) > 0:\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import numpy as np\n",
    "    \n",
    "    # Map FashionMNIST class indices to names\n",
    "    class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                  'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    \n",
    "    # Create and log confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    wandb.log({\"confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "        probs=None,\n",
    "        y_true=all_labels, \n",
    "        preds=all_preds,\n",
    "        class_names=class_names)\n",
    "    })\n",
    "    \n",
    "    # Log example predictions\n",
    "    example_images = [wandb.Image(img.reshape(28, 28), \n",
    "                                caption=f\"True: {class_names[true]}, Pred: {class_names[pred]}\") \n",
    "                      for img, true, pred in zip(all_images[:25], all_labels[:25], all_preds[:25])]\n",
    "    wandb.log({\"examples\": example_images})\n",
    "\n",
    "# Plot training and validation metrics\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(val_losses, label='Validation Loss', marker='o')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Training Accuracy', marker='o')\n",
    "plt.plot(val_accs, label='Validation Accuracy', marker='o')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Log the figure to wandb\n",
    "wandb.log({\"training_curves\": wandb.Image(plt)})\n",
    "\n",
    "# Print final results\n",
    "print(f\"Final training accuracy: {train_accs[-1]:.4f}\")\n",
    "print(f\"Final validation accuracy: {val_accs[-1]:.4f}\")\n",
    "\n",
    "# Add summary metrics\n",
    "wandb.summary['final_train_loss'] = train_losses[-1]\n",
    "wandb.summary['final_train_accuracy'] = train_accs[-1]\n",
    "wandb.summary['final_val_loss'] = val_losses[-1] \n",
    "wandb.summary['final_val_accuracy'] = val_accs[-1]\n",
    "\n",
    "# Close wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff733056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
