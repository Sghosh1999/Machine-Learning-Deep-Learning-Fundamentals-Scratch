{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c3d1b8f",
   "metadata": {},
   "source": [
    "# Daily Dose of Data Science\n",
    "\n",
    "The notebook accompanies the code for optimizing neural network training under memory constraints.\n",
    "\n",
    "[Gradient Accumulation: Increase Batch Size Without Explicitly Increasing Batch Size](https://www.blog.dailydoseofds.com/p/gradient-accumulation-increase-batch)\n",
    "\n",
    "Author: Avi Chawla"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28457b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:54:45.796357Z",
     "start_time": "2023-10-16T12:54:45.755358Z"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e65fb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:00.553519Z",
     "start_time": "2023-10-16T12:55:57.479033Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5748bd0",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc99090",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:01.728381Z",
     "start_time": "2023-10-16T12:56:01.497007Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb36393",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44010435",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:03.059784Z",
     "start_time": "2023-10-16T12:56:03.046874Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input tensor to a 2D tensor where the first dimension is the batch size\n",
    "        # and the second dimension is the flattened image (28*28 pixels).\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = torch.relu(self.fc1(x))\n",
    "        x2 = torch.relu(self.fc2(x1))\n",
    "        x3 = torch.relu(self.fc3(x2))\n",
    "        x4 = self.fc4(x3)\n",
    "        return x4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff670f5",
   "metadata": {},
   "source": [
    "## Evaluate model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e61e71a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:04.968952Z",
     "start_time": "2023-10-16T12:56:04.960089Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            outputs = model(inputs) # use last element returned by forward function\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d970cc92",
   "metadata": {},
   "source": [
    "## Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30dd44a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:08.617279Z",
     "start_time": "2023-10-16T12:56:08.599890Z"
    }
   },
   "outputs": [],
   "source": [
    "accumulation_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "683f15a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:56:38.453977Z",
     "start_time": "2023-10-16T12:56:09.784317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.38, Accuracy: 94.20%\n",
      "Epoch 2, Loss: 0.15, Accuracy: 95.68%\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for idx, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        if ((idx + 1) % accumulation_steps == 0) or ((idx+1) == len(trainloader)):\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    accuracy = evaluate(net)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e8e875",
   "metadata": {},
   "source": [
    "## Typical Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be09085c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-16T12:57:17.920030Z",
     "start_time": "2023-10-16T12:56:48.047582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.31, Accuracy: 94.87%\n",
      "Epoch 2, Loss: 0.15, Accuracy: 95.14%\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(2):\n",
    "    net.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for idx, data in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()            \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    accuracy = evaluate(net)\n",
    "        \n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
